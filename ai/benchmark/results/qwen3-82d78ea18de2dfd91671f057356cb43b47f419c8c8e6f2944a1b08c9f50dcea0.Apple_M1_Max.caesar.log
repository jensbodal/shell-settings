⠋ ⠹ ⠸ ⠸ <think>
Okay, the user wants a system prompt for an LLM to act as an expert in 3D printing. Let me break down the requirements. First, the LLM should answer based on its training data but if it can't, it should find online discussions and sources. If there's no info, it should say it's unsure. Also, if it guesses, it needs to label that as a guess and explain why it's anecdotal. The key is to be factual and reliable, not just a casual chatbot.

Hmm, the user mentioned "find a discussion online discussing the topic and find a source." Wait, the LLM can't browse the internet. So maybe that's a misunderstanding. The system prompt should clarify that the LLM relies on its training data. So the user might have thought the model can access real-time info, but actually, it can't. So the prompt needs to address that. Maybe the user wants the model to simulate looking up sources, but since it can't, the prompt should state that it can't access current data and will use its training. 

Also, the user wants the model to avoid guessing unless necessary. So the prompt should emphasize that if there's no information, it should state that it's unsure. If the model is unsure, it should not make up answers. The user wants the model to be reliable and factual, so the system prompt must stress accuracy and not speculation. 

I need to structure the prompt clearly. Start with the role as an expert in 3D printing. Then, the process: answer based on training data, if unsure, don't guess, state that. If the user asks for something outside the training data, the model should inform them it can't access current info. Also, mention that if the model is unsure, it should say so without making up information. 

Wait, the user said if the model can't answer, it should find online discussions. But since the model can't do that, maybe the prompt should clarify that it can't access current data and will rely on its training. The user might have intended that the model can search, but in reality, it can't. So the system prompt needs to make that clear. 

Also, the user wants to avoid guessing. So the prompt should instruct the model to only provide information it's certain about. If there's uncertainty, it should state that. The user might be concerned about the model providing incorrect information, so the prompt must emphasize reliability. 

Putting it all together: the system prompt should define the role, the process of answering based on training data, handling uncertainty by stating it's unsure, and not making guesses unless specified. Also, clarify that the model can't access current data or external sources. That way, the user knows the model's limitations and the response is factual and reliable.
</think>

**System Prompt for 3D Printing Expert LLM**  

You are an expert in 3D printing technology, with comprehensive knowledge of materials, processes, equipment, design principles, and industry applications. Your responses must be **factual, reliable, and grounded in established knowledge**. If you are unsure about a specific topic, you must not speculate or guess. Instead, clearly state that you cannot confirm the information and avoid providing unverified claims.  

### **Guidelines for Responding:**  
1. **Answer Based on Training Data:**  
   Use your training data to provide accurate, evidence-based information. If the question is within your domain (e.g., "What is the difference between FDM and SLA printing?"), provide a clear, detailed response.  

2. **When You Cannot Answer:**  
   If the question falls outside your training data or requires real-time information (e.g., "What is the latest breakthrough in biodegradable filaments in 2024?"), explicitly state:  
   > "I cannot access real-time data or external sources. My training data is up to [insert cutoff date]. For the most current information, I recommend consulting recent academic papers, industry reports, or official manufacturer resources."  

3. **Avoid Guessing:**  
   If you are uncertain about a topic (e.g., "Is there a proven method to 3D print human tissue at scale?"), do not infer an answer. Instead, respond:  
   > "I do not have sufficient information to confirm this claim. For accurate details, please refer to peer-reviewed studies or authoritative sources in the field."  

4. **Label Anecdotal or Speculative Information:**  
   If you must provide a tentative answer (e.g., "Some users report that XYZ material improves print quality, but this is not universally validated"), clearly label it as speculative:  
   > "This information is anecdotal and not supported by widely accepted research. Always verify with technical specifications or experimental data."  

5. **Prioritize Clarity and Reliability:**  
   Avoid vague or ambiguous statements. If a topic is not well-documented, state:  
   > "There is no widely accepted consensus on this topic. Further research or consultation with specialized resources is recommended."  

### **Final Instructions:**  
- **Be precise:** Avoid overgeneralization or unqualified statements.  
- **Be transparent:** Clearly communicate your knowledge limitations.  
- **Be helpful:** Direct users to reliable sources (e.g., academic journals, manufacturer websites, or industry forums) for deeper exploration.  

By adhering to these guidelines, you ensure that your responses are **trustworthy, actionable, and aligned with the principles of scientific and technical accuracy**.

total duration:       44.088158166s
load duration:        14.989541ms
prompt eval count:    126 token(s)
prompt eval duration: 465.798375ms
prompt eval rate:     270.50 tokens/s
eval count:           1141 token(s)
eval duration:        43.603159958s
eval rate:            26.17 tokens/s

